\documentclass[11pt]{article}
\input{prelude}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{multicol, latexsym, amssymb}
\usepackage{blindtext}
\usepackage{subcaption}
\usepackage{caption}
\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{tabu}

\begin{document}

\title{
{\textbf{CS591S1 Homework 2: More on Differential Privacy}}
}
\author{Jiawen Liu\\
Collaborators: none.}

\date{}
\maketitle

\section{Problem 1}

\begin{enumerate}
	\item (Sensitivity)

	Given data set $\data$, for arbitrary $y\in \{ 1, \cdots, R \}$ and adjacent dataset $\data'$ by insertion or deletion of one data point $x_k$, we have following cases for insertion (deletion will be symmetric):
	\begin{itemize}
		\item $y = x_k$:
		\[
		q(y; \data') 
		= - | \sum_{i = 0}^{n} sign(y - x_i) + sign( y - x_k) | 
		= - | \sum_{i = 0}^{n} sign(y - x_i) + 0 |
		= - | \sum_{i = 0}^{n} sign(y - x_i) |
		= q(y; \data)
		\]

		\item $y < x_k$
		%
		\[
		\begin{array}{rcl}
		q(y; \data') 
		& = &
		- | \sum_{i = 0}^{n} sign(y - x_i) + sign( y - x_k) | \\
		& = &
		- | \sum_{i = 0}^{n} sign(y - x_i) - 1 | ~ (\star)
		\end{array}
		\]
		%
		By triangle inequality, we have:
		\[
		\begin{array}{rcl}
		(\star) & 
		 \leq & 
		 - | \sum_{i = 0}^{n} sign(y - x_i) |  + 1
		= q(y; \data) + 1\\
		%
		(\star) &
		 \geq & 
		 - | \sum_{i = 0}^{n} sign(y - x_i) |  - 1
		 =
		 q(y; \data) - 1
		\end{array}
		\]
		%
		Then we can get:
		%
		\[
		-1 \leq q(y; \data') - q(y; \data) \leq 1
		\]
		%
		\item $y > x_k$
		%
		\[
		\begin{array}{rcl}
		q(y; \data') 
		& = &
		- | \sum_{i = 0}^{n} sign(y - x_i) + sign( y - x_k) | \\
		& = &
		- | \sum_{i = 0}^{n} sign(y - x_i) + 1 | ~ (\star)
		\end{array}
		\]
		%
		By triangle inequality, we have:
		\[
		\begin{array}{rcl}
		(\star) & 
		 \leq & 
		 - | \sum_{i = 0}^{n} sign(y - x_i) |  + 1
		= q(y; \data) + 1\\
		%
		(\star) &
		 \geq & 
		 - | \sum_{i = 0}^{n} sign(y - x_i) |  - 1
		 =
		 q(y; \data) - 1
		\end{array}
		\]
		%
		Then we can get:
		%
		\[
		-1 \leq q(y; \data') - q(y; \data) \leq 1
		\]
		%
	\end{itemize}
	The Deletion is symmetric where we can get: $-1 \leq q(y; \data) - q(y; \data') \leq 1$ in the same way.
	%
	\\
	%
	Then, we can conclude from all cases, the $| q(y; \data) - q(y; \data') | \leq 1$, i.e., the sensitivity be at most 1.
	%
	%
	\item 
	\begin{proof}
	By the definition of $rank_{\data}(y)$, we have:
	\[
	|rank_{\data}(y) - \frac{n}{2}| = - q(y; \data).
	\]
	Then, we know:
	%
	\[
	\begin{array}{lll}
	Pr_{y \sim A_{\epsilon}(\data)}[|rank_{\data}(y) - \frac{n}{2}|
	> 
	c \cdot \frac{\ln(R) + \ln(1 / \beta)}{\epsilon}] 
	& \equiv &
	Pr_{y \sim A_{\epsilon}(\data)}[- q(y; \data)
	> 
	c \cdot \frac{\ln(R) + \ln(1 / \beta)}{\epsilon}]\\
	& = &
	Pr_{y \sim A_{\epsilon}(\data)}[q(y; \data)
	\leq 
	- c \cdot \frac{\ln(R) + \ln(1 / \beta)}{\epsilon}]	
	\end{array}
	\]
	%
	By definition of exponential mechanism, we have:
	%
	\[
	\begin{array}{lll}
	Pr_{y \sim A_{\epsilon}(\data)}[q(y; \data)
	\leq 
	- c \cdot \frac{\ln(R) + \ln(1 / \beta)}{\epsilon}]
	& = &
	\sum\limits_{y| q(y; \data) < - c \cdot \frac{\ln(R) + \ln(1 / \beta)}{\epsilon}}
	\frac{\exp \big( q(y; \data)\epsilon / 2S \big)}
	{\sum\limits_{y}\exp \big( q(y; \data)\epsilon / 2S \big)}\\
	%
	& \leq &
	R
	\frac{\exp \big( - c \cdot \frac{\ln(R) + \ln(1 / \beta)}{\epsilon}
	\frac{\epsilon}{2S} \big)}
	{\sum\limits_{y}\exp \big( q(y; \data)\epsilon / 2S \big)}\\	
	%
	& = &
	R
	\frac{\exp \big(  \frac{c}{2} (\ln(\frac{1}{R}) + \ln(\beta)) \big)}
	{\sum\limits_{y}\exp \big( q(y; \data)\epsilon / 2S \big)} ~(\star)
	\end{array}
	\]
	%
	Since the only one optimal output candidate is the median value where $q(y, \data) = 0$, so we have:
	%
	\[
	\begin{array}{lll}
	(\star) & \leq &
	\frac{\exp \big(  \frac{c}{2} (\ln(\frac{1}{R}) + \ln(\beta)) \big)}
	{\exp ( 0)}\\	
	\end{array}
	\]
	%
	In order to have this probability be at most $\beta$, we take the equality and get:
	%
	\[
	\begin{array}{rcl}
	\frac{\exp \big(  \frac{c}{2} (\ln(\frac{1}{R}) + \ln(\beta)) \big)}
	{\exp ( 0)}
	& = & \beta\\
	R^{1 - \frac{c}{2}}	& = & \beta^{1 - \frac{c}{2}}
	\end{array}
	\]
	%
	Since we have $R \geq 1$ and $\beta \in (0,1)$, there exists $c = 2$ which can make the equation holds.
	%
	%
	\end{proof}
\end{enumerate}


\section{Problem 2}
\begin{proof}
The proof are developed by two symmetric cases: insertion and deletion.
%
\begin{itemize}
\caseL{Insertion}
Taking two adjacent data sets $\data$, $\data'$ where $\data'$ contains one more data point.
For any output set $S$, there are following cases by output space:
\begin{itemize} 
\item $S \subseteq E_{bad}$ Inserting one data that makes an empty bin ($k \in \domain$) be nonempty and this bin is contained in the output set $S$.
\[
	\begin{array}{rcl}
	Pr[A(\data') = S]
	& = & 
	Pr[\tilde{c'_k} > \tau ] \leq \frac{\delta}{2}\\
	Pr[A(\data) = S]
	& = & 0
	\end{array}
\]
\item $S \subseteq E_{0}$ Inserting one data that makes an empty bin ($k \in \domain$) be nonempty and this bin is not contained in the output set.The probability ratio 
%
\[
	\begin{array}{rcl}
	1 > \frac{Pr[A(\data') \in S]}
	{Pr[A(\data) \in S]}
	& = & 
	\frac{ Pr[A(\data) \in S \land \tilde{c'_k} < \tau ] }
	{Pr[A(\data) \in S]}\\
	& = &
	\frac{Pr[A(\data) \in S] \cdot Pr[ \tilde{c'_k} < \tau ] }
	{Pr[A(\data) \in S]}\\
	& = & 
	Pr[ \tilde{c'_k} = 1 + Lap(\frac{1}{\epsilon}) < \tau]\\
	& \geq &
	(1 - \frac{\delta}{2})
	\end{array}
\]

\item $S \subseteq E_{1}$ Inserting one data that doesn't change non-empty bins:
\[
	\begin{array}{rcl}
	e^{-\epsilon} \leq \frac{Pr[A(\data') \in S]}
	{Pr[A(\data) \in S]}
	& = & 
	\frac{Pr[A(\data \setminus k) \in S\setminus k 
	\land \tilde{c'_k} \in S \cap k]}
	{Pr[A(\data' \setminus k) \in S\setminus k 
	\land \tilde{c_k} \in S \cap k]}\\
	& = &
	\frac{Pr[A(\data \setminus k) = S\setminus k ] 
	\cdot Pr[\tilde{c'_k} \in S \cap k]}
	{Pr[A(\data \setminus k) = S\setminus k ] 
	\cdot Pr[\tilde{c'_k} \in S \cap k]}\\
	& = &
	\frac{Pr[ \tilde{c_k'} \in S \cap k]}
	{Pr[\tilde{c_k} \in S \cap k]}\\
	& \leq &
	e^{\epsilon}
	\end{array}
\]
\end{itemize}
By summarization, we have following equations:
%
\[
	\begin{array}{rcl}
	Pr[A(\data') \in S] & = & Pr[A(\data') \in S \cap E_0] + Pr[A(\data') \in S \cap E_1] + Pr[A(\data') \in S \cap E_{Bad}]\\
	& \leq & e^{\epsilon} Pr[A(\data) \in S \cap E_0] 
	+  Pr[A(\data) \in S \cap E_1] 
	+ \frac{\delta}{2}\\
	& \leq & e^{\epsilon} Pr[A(\data) \in S\cap E_0] 
	+ e^{\epsilon} Pr[A(\data) \in S\cap E_1] 
	+ \frac{\delta}{2}\\
	& = & e^{\epsilon} Pr[A(\data) \in S\cap (E_0 \cup E_1)] 
	+ \frac{\delta}{2}\\
	& \leq &
	e^{\epsilon} Pr[A(\data) \in S] 
	+ \frac{\delta}{2}\\
	\end{array}
\]

On the other side, we have:
\[
	\begin{array}{rcl}
	Pr[A(\data') \in S] & = & Pr[A(\data') \in S \cap E_0] + Pr[A(\data') \in S \cap E_1] + Pr[A(\data') \in S \cap E_{Bad}]\\
	&\geq & e^{-\epsilon} Pr[A(\data) \in S \cap E_0] 
	+  (1 - \frac{\delta}{2})Pr[A(\data) \in S \cap E_1] \\
	& \geq & \min(e^{-\epsilon}, 1 - \frac{\delta}{2}) 
	Pr[A(\data) \in S\cap E_0] 
	+ \min(e^{-\epsilon}, 1 - \frac{\delta}{2})
	Pr[A(\data) \in S\cap E_1]\\
	& = & \min(e^{-\epsilon}, 1 - \frac{\delta}{2}) Pr[A(\data) \in S\cap (E_0 \cup E_1)] \\
	& = &
	\min(e^{-\epsilon}, 1 - \frac{\delta}{2})
	Pr[A(\data) \in S] \\
	\end{array}
\]


\caseL{deletion.} By deletion, we have exactly the symmetric cases as insertion.


\end{itemize}
By summarization, the probability of failure would be $\delta$ in both cases. So we have the algorithm be $(\max(\epsilon, \ln(\frac{1}{1 - \frac{\delta}{2}})), \delta)$-DP. When $\delta$ is small, we have $\ln(\frac{1}{1 - \frac{\delta}{2}}) \sim 0$ and $\epsilon > 0$, then $(\max(\epsilon, \ln(\frac{1}{1 - \frac{\delta}{2}})), \delta)$-DP is $(\epsilon, \delta)$-DP.
\end{proof}



\end{document}
